# Simple LLM Implementation

This project provides an introductory walkthrough of basic Natural Language Processing (NLP) concepts using the **spaCy** library, as well as comparisons with other popular NLP libraries. It is ideal for those who are beginning their journey with Large Language Models (LLMs) and want to understand tokenization, embeddings, and vector space representations.

## üìò Overview

In this notebook, you will learn about:

- Key NLP concepts: **Token**, **Vocab**, **Sequence**
- Introduction to **spaCy** and its major features
- Installing and using `en_core_web_md`, a medium-sized English language model
- Performing tasks such as:
  - Tokenization
  - Accessing word vectors
  - Understanding similarity between words
- Comparison with other libraries such as Hugging Face Transformers, NLTK, Stanza, Flair, Gensim, AllenNLP, and TextBlob

## üõ†Ô∏è Technologies Used

- **Python 3**
- **spaCy**: Industrial-strength NLP library
- Jupyter Notebook for code and documentation

2. Open the notebook in Jupyter and follow along with the code and explanations.

## ‚ú® Features Demonstrated

- Tokenization and vector inspection using spaCy
- Embedding text into a vector space
- Semantic similarity demonstration
- Library comparison to help decide the best tool for your NLP use case

